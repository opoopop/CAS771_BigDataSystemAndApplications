{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 10: 1, 20: 2, 30: 3, 40: 4, 1: 5, 11: 6, 21: 7, 31: 8, 41: 9, 2: 10, 12: 11, 22: 12, 32: 13, 42: 14}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "all_class = [[0, 10, 20, 30, 40],\n",
    "             [1, 11, 21, 31, 41],\n",
    "             [2, 12, 22, 32, 42]]\n",
    "\n",
    "selected_classes=sum(all_class, [])\n",
    "label_mapping = {}\n",
    "label_idx = 0\n",
    "for st in all_class:\n",
    "    for orig_label in st:\n",
    "        label_mapping[orig_label] = label_idx\n",
    "        label_idx += 1\n",
    "\n",
    "\n",
    "print(label_mapping)\n",
    "\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "selected_indices_train = [\n",
    "    idx for idx, (_, label) in enumerate(train_set)\n",
    "    if label in selected_classes\n",
    "]\n",
    "\n",
    "\n",
    "for i in selected_indices_train:\n",
    "    train_set.targets[i]=label_mapping[train_set.targets[i]]\n",
    "\n",
    "\n",
    "bt_size=64\n",
    "# create filtered set\n",
    "filtered_train_set = Subset(train_set, selected_indices_train)\n",
    "\n",
    "train_loader = DataLoader(filtered_train_set, batch_size=bt_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=False, transform=transform_test\n",
    ")\n",
    "\n",
    "selected_indices_test = [\n",
    "    idx for idx, (_, label) in enumerate(test_set)\n",
    "    if label in selected_classes\n",
    "]\n",
    "#selected_indices_test=selected_indices_test[:100]\n",
    "\n",
    "for i in selected_indices_test:\n",
    "    test_set.targets[i]=label_mapping[test_set.targets[i]]\n",
    "\n",
    "filtered_test_set = Subset(test_set, selected_indices_test)\n",
    "test_loader = DataLoader(filtered_test_set, batch_size=bt_size, shuffle=False, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_0(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(CNN_0, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)  \n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  \n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)  \n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)  \n",
    "        self.bn3= nn.BatchNorm2d(512)\n",
    "\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # \n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 256)  \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn0(self.conv0(x))))\n",
    "\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # 64x64 -> 32x32\n",
    "\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # 32x32 -> 16x16\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "\n",
    "\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def create_classifier_list(file_list,device):\n",
    "    result=[]\n",
    "    # load classifiers\n",
    "    for f in file_list:\n",
    "        model =CNN_0() # \n",
    "        model.load_state_dict(torch.load(f))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        result.append(model)\n",
    "    return result\n",
    "classifier_file_list=[\n",
    "    '/home/chunjielu/CIFAR100classifier/model1/model_weights_CNN_0.pth',\n",
    "    '/home/chunjielu/CIFAR100classifier/model2/model_weights_CNN_0.pth',\n",
    "    '/home/chunjielu/CIFAR100classifier/model3/model_weights_CNN_0_41.pth'\n",
    "\n",
    "]\n",
    "classifier_list=create_classifier_list(classifier_file_list,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaModel(nn.Module):\n",
    "    def __init__(self, input_dim=15, hidden_dim1=128, hidden_dim2=64, num_classes=15):\n",
    "        super(MetaModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_meta_data(input,classifier_list):\n",
    "    \"\"\"\n",
    "    create the data as the input of meta model\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model_outputs = []\n",
    "        for model in classifier_list:\n",
    "                output = model(input)\n",
    "                model_outputs.append(output)\n",
    "\n",
    "        combined_outputs = torch.cat(model_outputs, dim=1)\n",
    "    return combined_outputs\n",
    "\n",
    "def train(model,optimizer,criterion,epoch=10,device='cpu'):\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epoch)\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        running_loss = 0.0 \n",
    "        for batch_idx, data in enumerate(train_loader, 0):\n",
    "            inputs, target = data\n",
    "            inputs, target = inputs.to(device) , target.to(device)\n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            outputs = model(get_meta_data(inputs,classifier_list))\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "      \n",
    "        if i%3==0 :\n",
    "            print('epoch: %d loss:%.3f ' % (i,running_loss), end=' ')\n",
    "            test(test_loader,model,criterion,device=device)\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "def test(test_loader,model,criterion,device='cpu'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_all=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device) , labels.to(device)\n",
    "            \n",
    "            outputs = model(get_meta_data(images,classifier_list))\n",
    "            loss_all+=criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy on test set: %.3f %%' % (100 * correct / total),end=' ')   \n",
    "    print('loss on test set: {:.3f} '.format(loss_all))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss:87.814  Accuracy on test set: 74.333 % loss on test set: 22.012 \n",
      "epoch: 3 loss:67.534  Accuracy on test set: 74.400 % loss on test set: 24.023 \n",
      "epoch: 6 loss:64.223  Accuracy on test set: 74.800 % loss on test set: 23.094 \n",
      "epoch: 9 loss:61.866  Accuracy on test set: 75.467 % loss on test set: 23.276 \n",
      "epoch: 12 loss:58.313  Accuracy on test set: 75.733 % loss on test set: 22.924 \n",
      "epoch: 15 loss:56.334  Accuracy on test set: 75.267 % loss on test set: 22.696 \n",
      "epoch: 18 loss:53.723  Accuracy on test set: 77.400 % loss on test set: 22.242 \n",
      "epoch: 21 loss:49.044  Accuracy on test set: 76.800 % loss on test set: 23.309 \n",
      "epoch: 24 loss:45.504  Accuracy on test set: 77.333 % loss on test set: 23.000 \n",
      "epoch: 27 loss:44.860  Accuracy on test set: 76.733 % loss on test set: 23.967 \n"
     ]
    }
   ],
   "source": [
    "model = MetaModel()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4) \n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train(model,optimizer,criterion,epoch=30,device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 77.667 % loss on test set: 21.908 \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test(test_loader,model,criterion,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"./meta/meta_model_1.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
